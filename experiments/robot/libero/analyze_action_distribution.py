#!/usr/bin/env python3
"""
analyze_action_distribution.py

Analyzes action distributions from the JSON file generated by run_libero_eval.py.
Computes mean and standard deviation for each DOF across time steps for different temperature settings.
"""

import json
import numpy as np
import matplotlib.pyplot as plt
import argparse
from typing import Dict
from sklearn.decomposition import PCA


def load_action_data(json_file: str) -> Dict:
    """Load action distribution data from JSON file."""
    with open(json_file, 'r') as f:
        return json.load(f)


def filter_data_by_task(data: Dict, task_id: int = None) -> Dict:
    """Filter data by task ID if specified."""
    if task_id is None:
        return data
    
    filtered_data = {}
    for key, value in data.items():
        if 'task_id' in value and value['task_id'] == task_id:
            filtered_data[key] = value
    
    return filtered_data


def analyze_action_distribution(data: Dict, temperature: float) -> Dict:
    """
    Analyze action distribution for a specific temperature setting.
    
    Args:
        data: Loaded JSON data
        temperature: Temperature setting to analyze
        
    Returns:
        Dictionary containing analysis results
    """
    # Find the entry for this temperature
    temp_key = None
    for key, value in data.items():
        if value.get('temperature') == temperature:
            temp_key = key
            break
    
    if temp_key is None:
        raise ValueError(f"No data found for temperature {temperature}")
    
    action_data = data[temp_key]
    action_distributions = action_data['action_distributions']
    
    # Collect all actions across episodes for each timestep
    timestep_actions = {}
    
    for episode_id, episode_actions in action_distributions.items():
        for timestep, action in enumerate(episode_actions):
            if timestep not in timestep_actions:
                timestep_actions[timestep] = []
            timestep_actions[timestep].append(action)
    
    # Compute statistics for each timestep
    analysis_results = {
        'temperature': temperature,
        'do_sample': action_data['do_sample'],
        'task_description': action_data['task_description'],
        'num_episodes': action_data['num_episodes'],
        'success_rate': action_data['success_rate'],
        'timestep_stats': {}
    }
    
    for timestep, actions in timestep_actions.items():
        actions_array = np.array(actions)  # Shape: (num_episodes, action_dim)
        
        # Compute mean and std for each DOF
        mean_actions = np.mean(actions_array, axis=0)
        std_actions = np.std(actions_array, axis=0)
        
        analysis_results['timestep_stats'][timestep] = {
            'mean': mean_actions.tolist(),
            'std': std_actions.tolist(),
            'num_episodes': len(actions)
        }
    
    return analysis_results


def plot_action_distribution(analysis_results: Dict, output_dir: str = None):
    """
    Plot action distribution analysis results.
    
    Args:
        analysis_results: Results from analyze_action_distribution
        output_dir: Directory to save plots (optional)
    """
    timesteps = sorted(analysis_results['timestep_stats'].keys())
    num_dofs = len(analysis_results['timestep_stats'][timesteps[0]]['mean'])
    
    # Create subplots for each DOF
    fig, axes = plt.subplots(num_dofs, 1, figsize=(12, 3 * num_dofs))
    if num_dofs == 1:
        axes = [axes]
    
    dof_names = ['x', 'y', 'z', 'rx', 'ry', 'rz', 'gripper']
    
    for dof_idx in range(num_dofs):
        means = []
        stds = []
        
        for timestep in timesteps:
            stats = analysis_results['timestep_stats'][timestep]
            means.append(stats['mean'][dof_idx])
            stds.append(stats['std'][dof_idx])
        
        # Plot mean with error bars (dotted lines for std)
        axes[dof_idx].errorbar(timesteps, means, yerr=stds, 
                              label=f'Mean ± Std', capsize=3, capthick=1,
                              linestyle='-', alpha=0.7)
        axes[dof_idx].plot(timesteps, means, 'o-', markersize=4, linewidth=2, label='Mean')
        
        # Add dotted lines for upper and lower bounds
        upper_bounds = [m + s for m, s in zip(means, stds)]
        lower_bounds = [m - s for m, s in zip(means, stds)]
        axes[dof_idx].plot(timesteps, upper_bounds, '--', alpha=0.5, linewidth=1, color='gray', label='±1 Std')
        axes[dof_idx].plot(timesteps, lower_bounds, '--', alpha=0.5, linewidth=1, color='gray')
        
        axes[dof_idx].set_xlabel('Timestep')
        axes[dof_idx].set_ylabel(f'Action Value (DOF {dof_idx}: {dof_names[dof_idx] if dof_idx < len(dof_names) else f"DOF_{dof_idx}"})')
        axes[dof_idx].set_title(f'Action Distribution - DOF {dof_idx} ({dof_names[dof_idx] if dof_idx < len(dof_names) else f"DOF_{dof_idx}"})')
        axes[dof_idx].grid(True, alpha=0.3)
        axes[dof_idx].legend()
    
    plt.tight_layout()
    
    # Save plot if output directory is specified
    if output_dir:
        os.makedirs(output_dir, exist_ok=True)
        temp = analysis_results['temperature']
        do_sample = analysis_results['do_sample']
        filename = f"action_distribution_temp_{temp}_sample_{do_sample}.png"
        filepath = os.path.join(output_dir, filename)
        plt.savefig(filepath, dpi=300, bbox_inches='tight')
        print(f"Plot saved to: {filepath}")
    
    plt.show()


def summarize_by_phases(analysis_results: Dict, phases: int = 3) -> Dict:
    """
    Summarize per-DoF stats across a small number of phases instead of all timesteps.

    Returns a dict with per-DoF arrays of mean|std over each phase:
    {
      'phase_indices': [(start,end),...],
      'mean_abs': np.ndarray[num_dofs, phases],
      'std': np.ndarray[num_dofs, phases]
    }
    """
    timesteps = sorted(analysis_results['timestep_stats'].keys())
    num_steps = len(timesteps)
    if num_steps == 0:
        return {'phase_indices': [], 'mean_abs': np.array([]), 'std': np.array([])}

    num_dofs = len(analysis_results['timestep_stats'][timesteps[0]]['mean'])

    # Determine phase boundaries
    phase_sizes = [num_steps // phases] * phases
    for i in range(num_steps % phases):
        phase_sizes[i] += 1
    bounds = []
    start = 0
    for size in phase_sizes:
        end = start + size
        bounds.append((start, end))
        start = end

    mean_abs = np.zeros((num_dofs, phases))
    std_vals = np.zeros((num_dofs, phases))

    means_over_time = np.array([analysis_results['timestep_stats'][t]['mean'] for t in timesteps])
    stds_over_time = np.array([analysis_results['timestep_stats'][t]['std'] for t in timesteps])

    for p_idx, (s, e) in enumerate(bounds):
        if s >= e:
            continue
        seg_means = np.abs(means_over_time[s:e, :])
        seg_stds = stds_over_time[s:e, :]
        mean_abs[:, p_idx] = seg_means.mean(axis=0)
        std_vals[:, p_idx] = seg_stds.mean(axis=0)

    return {'phase_indices': bounds, 'mean_abs': mean_abs, 'std': std_vals}


def plot_summary_bars(analysis_results: Dict, phases: int = 3, output_dir: str = None):
    """Plot compact per-DoF bars over phases for |mean| and std."""
    dof_names = ['x', 'y', 'z', 'rx', 'ry', 'rz', 'gripper']
    summary = summarize_by_phases(analysis_results, phases)
    if summary['mean_abs'].size == 0:
        print('No data to summarize.')
        return

    num_dofs = summary['mean_abs'].shape[0]

    # Mean magnitude bars
    fig1, ax1 = plt.subplots(figsize=(12, 4))
    width = 0.8 / phases
    idx = np.arange(num_dofs)
    for p in range(phases):
        ax1.bar(idx + p * width, summary['mean_abs'][:, p], width=width, label=f'Phase {p+1}')
    ax1.set_xticks(idx + 0.4)
    ax1.set_xticklabels([dof_names[i] if i < len(dof_names) else f'DOF_{i}' for i in range(num_dofs)])
    ax1.set_ylabel('|Mean(action)|')
    ax1.set_title('Per-DoF Mean Magnitude by Phase')
    ax1.grid(True, axis='y', alpha=0.3)
    ax1.legend()
    plt.tight_layout()

    if output_dir:
        os.makedirs(output_dir, exist_ok=True)
        temp = analysis_results['temperature']
        do_sample = analysis_results['do_sample']
        fp = os.path.join(output_dir, f'action_summary_mean_temp_{temp}_sample_{do_sample}.png')
        plt.savefig(fp, dpi=300, bbox_inches='tight')
        print(f'Summary mean bars saved: {fp}')

    # Std bars
    fig2, ax2 = plt.subplots(figsize=(12, 4))
    for p in range(phases):
        ax2.bar(idx + p * width, summary['std'][:, p], width=width, label=f'Phase {p+1}')
    ax2.set_xticks(idx + 0.4)
    ax2.set_xticklabels([dof_names[i] if i < len(dof_names) else f'DOF_{i}' for i in range(num_dofs)])
    ax2.set_ylabel('Std(action)')
    ax2.set_title('Per-DoF Std by Phase')
    ax2.grid(True, axis='y', alpha=0.3)
    ax2.legend()
    plt.tight_layout()

    if output_dir:
        os.makedirs(output_dir, exist_ok=True)
        temp = analysis_results['temperature']
        do_sample = analysis_results['do_sample']
        fp = os.path.join(output_dir, f'action_summary_std_temp_{temp}_sample_{do_sample}.png')
        plt.savefig(fp, dpi=300, bbox_inches='tight')
        print(f'Summary std bars saved: {fp}')

    plt.show()


def plot_std_heatmap(analysis_results: Dict, output_dir: str = None):
    """Plot a heatmap of per-DoF std across timesteps (compact view)."""
    timesteps = sorted(analysis_results['timestep_stats'].keys())
    stds_over_time = np.array([analysis_results['timestep_stats'][t]['std'] for t in timesteps])
    # Shape: (T, D) -> transpose for DoF rows
    H = stds_over_time.T
    dof_names = ['x', 'y', 'z', 'rx', 'ry', 'rz', 'gripper']

    plt.figure(figsize=(min(14, max(8, len(timesteps) / 6)), 3.5))
    im = plt.imshow(H, aspect='auto', interpolation='nearest', cmap='magma')
    plt.colorbar(im, label='Std(action)')
    plt.yticks(range(H.shape[0]), [dof_names[i] if i < len(dof_names) else f'DOF_{i}' for i in range(H.shape[0])])
    plt.xlabel('Timestep')
    plt.title('Per-DoF Std Heatmap')
    plt.tight_layout()

    if output_dir:
        os.makedirs(output_dir, exist_ok=True)
        temp = analysis_results['temperature']
        do_sample = analysis_results['do_sample']
        fp = os.path.join(output_dir, f'action_std_heatmap_temp_{temp}_sample_{do_sample}.png')
        plt.savefig(fp, dpi=300, bbox_inches='tight')
        print(f'Heatmap saved: {fp}')

    plt.show()


def compare_temperatures(data: Dict, temperatures: List[float], output_dir: str = None):
    """
    Compare action distributions across different temperature settings.
    
    Args:
        data: Loaded JSON data
        temperatures: List of temperatures to compare
        output_dir: Directory to save plots (optional)
    """
    num_dofs = 7  # Assuming 7 DOF (x, y, z, rx, ry, rz, gripper)
    dof_names = ['x', 'y', 'z', 'rx', 'ry', 'rz', 'gripper']
    
    fig, axes = plt.subplots(num_dofs, 1, figsize=(15, 4 * num_dofs))
    if num_dofs == 1:
        axes = [axes]
    
    colors = plt.cm.viridis(np.linspace(0, 1, len(temperatures)))
    
    for temp_idx, temperature in enumerate(temperatures):
        try:
            analysis = analyze_action_distribution(data, temperature)
            timesteps = sorted(analysis['timestep_stats'].keys())
            
            for dof_idx in range(num_dofs):
                means = []
                stds = []
                
                for timestep in timesteps:
                    stats = analysis['timestep_stats'][timestep]
                    means.append(stats['mean'][dof_idx])
                    stds.append(stats['std'][dof_idx])
                
                # Plot mean with error bars (dotted lines for std)
                # axes[dof_idx].errorbar(timesteps, means, yerr=stds, 
                #                       label=f'Temp {temperature}', capsize=2, capthick=1,
                #                       color=colors[temp_idx], alpha=0.4, linestyle='--')
                axes[dof_idx].plot(timesteps, means, 'o-', markersize=3, 
                                  color=colors[temp_idx], alpha=0.9, linewidth=2)
                
                # Add dotted lines for upper and lower bounds
                # upper_bounds = [m + s for m, s in zip(means, stds)]
                # lower_bounds = [m - s for m, s in zip(means, stds)]
                # axes[dof_idx].plot(timesteps, upper_bounds, '--', alpha=0.4, linewidth=1, 
                #                   color=colors[temp_idx])
                # axes[dof_idx].plot(timesteps, lower_bounds, '--', alpha=0.4, linewidth=1, 
                #                   color=colors[temp_idx])
        
        except ValueError as e:
            print(f"Warning: {e}")
            continue
    
    for dof_idx in range(num_dofs):
        axes[dof_idx].set_xlabel('Timestep')
        axes[dof_idx].set_ylabel(f'Action Value (DOF {dof_idx}: {dof_names[dof_idx]})')
        axes[dof_idx].set_title(f'Action Distribution Comparison - DOF {dof_idx} ({dof_names[dof_idx]})')
        axes[dof_idx].grid(True, alpha=0.3)
        axes[dof_idx].legend()
    
    plt.tight_layout()
    
    # Save plot if output directory is specified
    if output_dir:
        os.makedirs(output_dir, exist_ok=True)
        filename = f"action_distribution_comparison.png"
        filepath = os.path.join(output_dir, filename)
        plt.savefig(filepath, dpi=300, bbox_inches='tight')
        print(f"Comparison plot saved to: {filepath}")
    
    plt.show()


def analyze_pca_components(data: Dict, n_components: int = 3) -> Dict:
    """
    Perform PCA analysis and compute mean/variance of PCA components across timesteps for different temperatures.
    
    Args:
        data: Loaded JSON data
        n_components: Number of PCA components to use
        
    Returns:
        Dictionary containing PCA analysis results for each temperature
    """
    results = {}
    
    for key, value in data.items():
        if 'temperature' not in value:
            continue
            
        temperature = value['temperature']
        action_distributions = value['action_distributions']
        
        # Collect all actions for this temperature
        all_actions = []
        for episode_id, episode_actions in action_distributions.items():
            all_actions.extend(episode_actions)
        
        if not all_actions:
            continue
            
        # Convert to numpy array
        all_actions = np.array(all_actions)  # (total_samples, action_dim)
        
        # Fit PCA on all actions for this temperature
        pca = PCA(n_components=n_components, random_state=42)
        pca_components = pca.fit_transform(all_actions)
        
        # Group by timestep and compute statistics
        timestep_stats = {}
        max_timestep = 0
        
        # Find max timestep across all episodes
        for episode_id, episode_actions in action_distributions.items():
            max_timestep = max(max_timestep, len(episode_actions))
        
        # For each timestep, collect PCA components and compute stats
        for timestep in range(max_timestep):
            timestep_components = []
            
            for episode_id, episode_actions in action_distributions.items():
                if timestep < len(episode_actions):
                    # Get the action at this timestep
                    action = episode_actions[timestep]
                    # Transform to PCA space
                    pca_action = pca.transform([action])[0]
                    timestep_components.append(pca_action)
            
            if timestep_components:
                timestep_components = np.array(timestep_components)
                
                # Compute mean and std for each PCA component
                means = np.mean(timestep_components, axis=0)
                stds = np.std(timestep_components, axis=0)
                
                timestep_stats[timestep] = {
                    'mean': means.tolist(),
                    'std': stds.tolist(),
                    'num_episodes': len(timestep_components)
                }
        
        results[key] = {
            'temperature': temperature,
            'do_sample': value['do_sample'],
            'task_description': value['task_description'],
            'success_rate': value['success_rate'],
            'pca_components': timestep_stats,
            'explained_variance_ratio': pca.explained_variance_ratio_.tolist(),
            'pca_components_names': [f'PC{i+1}' for i in range(n_components)]
        }
    
    return results


def plot_pca_components(pca_results: Dict, output_dir: str = None):
    """
    Plot PCA components mean and variance across timesteps for different temperatures.
    
    Args:
        pca_results: Results from analyze_pca_components
        output_dir: Directory to save plots
    """
    # Get number of components from first result
    first_key = list(pca_results.keys())[0]
    n_components = len(pca_results[first_key]['pca_components_names'])
    
    # Create subplots for each PCA component
    fig, axes = plt.subplots(n_components, 1, figsize=(12, 4 * n_components))
    if n_components == 1:
        axes = [axes]
    
    colors = plt.cm.viridis(np.linspace(0, 1, len(pca_results)))
    
    for temp_idx, (key, result) in enumerate(pca_results.items()):
        temperature = result['temperature']
        do_sample = result['do_sample']
        success_rate = result['success_rate']
        pca_components = result['pca_components']
        component_names = result['pca_components_names']
        explained_variance = result['explained_variance_ratio']
        
        timesteps = sorted(pca_components.keys())
        
        for comp_idx in range(n_components):
            means = []
            stds = []
            
            for timestep in timesteps:
                stats = pca_components[timestep]
                means.append(stats['mean'][comp_idx])
                stds.append(stats['std'][comp_idx])
            
            # Plot mean line
            sample_str = "Sample" if do_sample else "No Sample"
            success_str = f"{success_rate:.0%}"
            axes[comp_idx].plot(timesteps, means, '-', 
                               label=f'Temp {temperature}, {sample_str}, {success_str} (var={explained_variance[comp_idx]:.3f})', 
                               color=colors[temp_idx], linewidth=2)
            
            # Fill between for standard deviation
            upper_bounds = [m + s for m, s in zip(means, stds)]
            lower_bounds = [m - s for m, s in zip(means, stds)]
            axes[comp_idx].fill_between(timesteps, upper_bounds, lower_bounds, 
                                       alpha=0.15, color=colors[temp_idx])
    
    # Configure subplots
    for comp_idx in range(n_components):
        axes[comp_idx].set_xlabel('Timestep')
        axes[comp_idx].set_ylabel(f'PCA Component {comp_idx+1} Value')
        axes[comp_idx].set_title(f'PCA Component {comp_idx+1} - Mean ± Std Across Timesteps')
        axes[comp_idx].grid(True, alpha=0.3)
        axes[comp_idx].legend()
    
    plt.tight_layout()
    
    if output_dir:
        os.makedirs(output_dir, exist_ok=True)
        filepath = os.path.join(output_dir, 'pca_components_analysis.png')
        plt.savefig(filepath, dpi=300, bbox_inches='tight')
        print(f"PCA components plot saved to: {filepath}")
    
    plt.show()


def print_pca_summary(pca_results: Dict):
    """Print summary of PCA analysis results."""
    print(f"\n=== PCA Components Analysis ===")
    
    for key, result in pca_results.items():
        temperature = result['temperature']
        do_sample = result['do_sample']
        explained_variance = result['explained_variance_ratio']
        component_names = result['pca_components_names']
        
        print(f"\nTemperature: {temperature}, Do Sample: {do_sample}")
        print(f"Explained Variance Ratio: {[f'{v:.3f}' for v in explained_variance]}")
        print(f"Total Explained Variance: {sum(explained_variance):.3f}")
        
        # Compute overall statistics for each component
        pca_components = result['pca_components']
        timesteps = sorted(pca_components.keys())
        
        for comp_idx, comp_name in enumerate(component_names):
            means = [pca_components[t]['mean'][comp_idx] for t in timesteps]
            stds = [pca_components[t]['std'][comp_idx] for t in timesteps]
            
            print(f"  {comp_name}:")
            print(f"    Mean of means: {np.mean(means):.6f}")
            print(f"    Std of means:  {np.std(means):.6f}")
            print(f"    Mean of stds:  {np.mean(stds):.6f}")
            print(f"    Std of stds:   {np.std(stds):.6f}")


def print_summary_statistics(analysis_results: Dict):
    """Print summary statistics for the analysis."""
    print(f"\n=== Action Distribution Analysis ===")
    print(f"Temperature: {analysis_results['temperature']}")
    print(f"Do Sample: {analysis_results['do_sample']}")
    print(f"Task: {analysis_results['task_description']}")
    print(f"Number of Episodes: {analysis_results['num_episodes']}")
    print(f"Success Rate: {analysis_results['success_rate']:.2%}")
    
    timesteps = sorted(analysis_results['timestep_stats'].keys())
    print(f"Number of Timesteps: {len(timesteps)}")
    
    # Compute overall statistics
    all_means = []
    all_stds = []
    
    for timestep in timesteps:
        stats = analysis_results['timestep_stats'][timestep]
        all_means.append(stats['mean'])
        all_stds.append(stats['std'])
    
    all_means = np.array(all_means)
    all_stds = np.array(all_stds)
    
    print(f"\n=== Overall Statistics Across All Timesteps ===")
    dof_names = ['x', 'y', 'z', 'rx', 'ry', 'rz', 'gripper']
    
    for dof_idx in range(all_means.shape[1]):
        dof_means = all_means[:, dof_idx]
        dof_stds = all_stds[:, dof_idx]
        
        print(f"DOF {dof_idx} ({dof_names[dof_idx] if dof_idx < len(dof_names) else f'DOF_{dof_idx}'}):")
        print(f"  Mean of means: {np.mean(dof_means):.6f}")
        print(f"  Std of means:  {np.std(dof_means):.6f}")
        print(f"  Mean of stds:  {np.mean(dof_stds):.6f}")
        print(f"  Std of stds:   {np.std(dof_stds):.6f}")


def main():
    parser = argparse.ArgumentParser(description='Analyze action distributions from LIBERO evaluation')
    parser.add_argument('--json_file', type=str, 
                       default='/data/user/san/openvla/experiments/robot/libero/tmp/action_sampling.json',
                       help='Path to the JSON file containing action distributions')
    parser.add_argument('--temperature', type=float, default=None,
                       help='Specific temperature to analyze (if not provided, analyzes all)')
    parser.add_argument('--task', type=int, default=0,
                       help='Specific task ID to analyze (default: 0)')
    parser.add_argument('--output_dir', type=str, default='./action_analysis_plots',
                       help='Base directory to save plots (will create task-specific subdirectories)')
    parser.add_argument('--compare', action='store_true',
                       help='Compare all available temperatures')
    parser.add_argument('--summary', action='store_true',
                       help='Plot compact per-DoF phase summary bars instead of full timeline')
    parser.add_argument('--heatmap', action='store_true',
                       help='Plot per-DoF std heatmap (compact)')
    parser.add_argument('--pca', action='store_true',
                       help='Perform PCA analysis and plot components across timesteps')
    parser.add_argument('--n_components', type=int, default=3,
                       help='Number of PCA components to use (default: 3)')
    parser.add_argument('--phases', type=int, default=3,
                       help='Number of phases for summary view')
    
    args = parser.parse_args()
    
    # Load data
    print(f"Loading data from: {args.json_file}")
    data = load_action_data(args.json_file)
    
    # Filter by task (default is 0)
    data = filter_data_by_task(data, args.task)
    print(f"Filtered data for task ID: {args.task}")
    if not data:
        print(f"No data found for task ID {args.task}")
        return
    
    # Create task-specific output directory
    task_output_dir = os.path.join(args.output_dir, f"task_{args.task}")
    print(f"Output directory: {task_output_dir}")
    
    # Get available temperatures
    available_temps = set()
    for key, value in data.items():
        if 'temperature' in value:
            available_temps.add(value['temperature'])
    
    print(f"Available temperatures: {sorted(available_temps)}")
    
    # Get available tasks
    available_tasks = set()
    for key, value in data.items():
        if 'task_id' in value:
            available_tasks.add(value['task_id'])
    
    print(f"Available tasks: {sorted(available_tasks)}")
    
    if args.pca:
        # Perform PCA analysis
        print(f"\nPerforming PCA analysis with {args.n_components} components...")
        pca_results = analyze_pca_components(data, n_components=args.n_components)
        print_pca_summary(pca_results)
        plot_pca_components(pca_results, task_output_dir)
    elif args.compare:
        # Compare all temperatures
        print("\nComparing all available temperatures...")
        compare_temperatures(data, sorted(available_temps), task_output_dir)
    elif args.temperature is not None:
        # Analyze specific temperature
        if args.temperature not in available_temps:
            print(f"Error: Temperature {args.temperature} not found in data")
            return
        
        print(f"\nAnalyzing temperature: {args.temperature}")
        analysis = analyze_action_distribution(data, args.temperature)
        print_summary_statistics(analysis)
        if args.summary:
            plot_summary_bars(analysis, phases=args.phases, output_dir=task_output_dir)
        elif args.heatmap:
            plot_std_heatmap(analysis, output_dir=task_output_dir)
        else:
            plot_action_distribution(analysis, task_output_dir)
    else:
        # Analyze all temperatures individually
        for temp in sorted(available_temps):
            print(f"\nAnalyzing temperature: {temp}")
            analysis = analyze_action_distribution(data, temp)
            print_summary_statistics(analysis)
            if args.summary:
                plot_summary_bars(analysis, phases=args.phases, output_dir=task_output_dir)
            elif args.heatmap:
                plot_std_heatmap(analysis, output_dir=task_output_dir)
            else:
                plot_action_distribution(analysis, task_output_dir)


if __name__ == "__main__":
    import os
    main()
